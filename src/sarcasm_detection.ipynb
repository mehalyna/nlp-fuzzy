{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarcasm detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ideas:\n",
    "- Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ðµ Ð²Ð¸ÑÐ²Ð»ÐµÐ½Ð½Ñ ÑÐ°Ñ€ÐºÐ°Ð·Ð¼Ñƒ Ð² ÑÐ¾Ñ† Ð¼ÐµÑ€ÐµÐ¶Ð°Ñ… (Ñ‚Ð²Ñ–Ñ‚Ñ‚ÐµÑ€ etc)\n",
    "- Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ñ–Ñ ÑÐ°Ñ€ÐºÐ°ÑÑ‚Ð¸Ñ‡Ð½Ð¸Ñ… Ð²Ð¸ÑÐ»Ð¾Ð²Ð»ÑŽÐ²Ð°Ð½ÑŒ \n",
    "- Ð°Ð½Ð°Ð»Ñ–Ð· Ð²Ð¿Ð»Ð¸Ð²Ñƒ ÐµÐ¼Ð¾Ð´Ð·Ñ– Ð¿ÑƒÐ½ÐºÑ‚ÑƒÐ°Ñ†Ñ–Ñ \n",
    "- ÑÐ°Ñ€ÐºÐ°Ð·Ð¼ Ñƒ Ñ€Ñ–Ð·Ð½Ð¸Ñ… ÐºÑƒÐ»ÑŒÑ‚ÑƒÑ€Ð°Ñ… Ð¿Ð¾Ñ€Ñ–Ð²Ð½ÑÐ½Ð½Ñ \n",
    "- Ð² Ð¿Ð¾Ð»Ñ–Ñ‚Ð¸Ñ‡Ð½Ð¸Ñ… Ñ‚ÐµÐºÑÑ‚Ð°Ñ…\n",
    "- Ð² Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ð¾Ð¼Ñƒ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñ– (Ñ‚ÐµÐºÑÑ‚ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ Ð³Ð¾Ð»Ð¾Ñ)\n",
    "- Ñƒ Ð½Ð¾Ð²Ð¸Ð½Ð°Ñ… Ñ‚Ð° Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°Ñ…\n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports section\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from gensim import corpora, models, similarities\n",
    "import string\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign mood scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = {\n",
    "    \"anxious\": 0.1, \"furious\": 0.0, \"peaceful\": 0.9, \"hate\": 0.0, \"joyful\": 0.9, \n",
    "    \"unacceptable\": 0.1, \"thrilled\": 0.9, \"infuriating\": 0.1, \"irate\": 0.1, \n",
    "    \"terrible\": 0.1, \"nervous\": 0.2, \"melancholy\": 0.3, \"depressed\": 0.1, \n",
    "    \"gloomy\": 0.1, \"serene\": 0.8, \"elated\": 0.8, \"ecstatic\": 0.9, \"overjoyed\": 0.9,\n",
    "    \"gleeful\": 0.7, \"cheerful\": 0.7, \"optimistic\": 0.7, \"buoyant\": 0.6, \n",
    "    \"enthusiastic\": 0.7, \"upbeat\": 0.6, \"festive\": 0.6, \"playful\": 0.6,\n",
    "    \"vivacious\": 0.6, \"amused\": 0.7, \"blissful\": 0.6, \"grateful\": 0.8,\n",
    "    \"tranquil\": 0.8, \"relaxed\": 0.7, \"comfortable\": 0.6, \"cozy\": 0.6,\n",
    "    \"warm\": 0.6, \"inviting\": 0.6,  \"satisfied\": 0.5, \"pleasant\": 0.6, \n",
    "    \"pleased\" : 0.7, \"happy\": 0.8\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read adjectives from txt file and define array of given adjactive scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.6298e-01  3.0141e-01  5.7978e-01  6.6548e-02  4.5835e-01 -1.5329e-01\n",
      "  4.3258e-01 -8.9215e-01  5.7747e-01  3.6375e-01  5.6524e-01 -5.6281e-01\n",
      "  3.5659e-01 -3.6096e-01 -9.9662e-02  5.2753e-01  3.8839e-01  9.6185e-01\n",
      "  1.8841e-01  3.0741e-01 -8.7842e-01 -3.2442e-01  1.1202e+00  7.5126e-02\n",
      "  4.2661e-01 -6.0651e-01 -1.3893e-01  4.7862e-02 -4.5158e-01  9.3723e-02\n",
      "  1.7463e-01  1.0962e+00 -1.0044e+00  6.3889e-02  3.8002e-01  2.1109e-01\n",
      " -6.6247e-01 -4.0736e-01  8.9442e-01 -6.0974e-01 -1.8577e-01 -1.9913e-01\n",
      " -6.9226e-01 -3.1806e-01 -7.8565e-01  2.3831e-01  1.2992e-01  8.7721e-02\n",
      "  4.3205e-01 -2.2662e-01  3.1549e-01 -3.1748e-01 -2.4632e-03  1.6615e-01\n",
      "  4.2358e-01 -1.8087e+00 -3.6699e-01  2.3949e-01  2.5458e+00  3.6111e-01\n",
      "  3.9486e-02  4.8607e-01 -3.6974e-01  5.7282e-02 -4.9317e-01  2.2765e-01\n",
      "  7.9966e-01  2.1428e-01  6.9811e-01  1.1262e+00 -1.3526e-01  7.1972e-01\n",
      " -9.9605e-04 -2.6842e-01 -8.3038e-01  2.1780e-01  3.4355e-01  3.7731e-01\n",
      " -4.0251e-01  3.3124e-01  1.2576e+00 -2.7196e-01 -8.6093e-01  9.0053e-02\n",
      " -2.4876e+00  4.5200e-01  6.6945e-01 -5.4648e-01 -1.0324e-01 -1.6979e-01\n",
      "  5.9437e-01  1.1280e+00  7.5755e-01 -5.9160e-02  1.5152e-01 -2.8388e-01\n",
      "  4.9452e-01 -9.1703e-01  9.1289e-01 -3.0927e-01]\n"
     ]
    }
   ],
   "source": [
    "corpus = api.load('glove-wiki-gigaword-100')\n",
    "\n",
    "vector = corpus['computer']\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ''\n",
    "\n",
    "with open('../resources/sets/english-adjectives.txt', 'r') as file:\n",
    "    data = file.read().replace('\\n', ',')\n",
    "\n",
    "adjectives = data.split(',')\n",
    "\n",
    "adjectives_scored = {}\n",
    "\n",
    "for adjective in adjectives:\n",
    "    if adjective in corpus:\n",
    "        adjectives_scored[adjective] = corpus[adjective]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrapolate mood scores to adjactives using ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abandoned : 0.5502134408623401\n",
      "able : 0.5738754788141942\n",
      "absolute : 0.5533041141904692\n",
      "adorable : 0.6850831336397633\n",
      "adventurous : 0.7317279837933087\n",
      "academic : 0.6067780394909661\n",
      "acceptable : 0.5418516265597876\n",
      "acclaimed : 0.632770424842083\n",
      "accomplished : 0.7002035117922148\n",
      "accurate : 0.5961909093757255\n",
      "aching : 0.5120204820087043\n",
      "acidic : 0.609821719098859\n",
      "acrobatic : 0.5990260157303468\n",
      "active : 0.6171011830678385\n",
      "actual : 0.5642501235517013\n",
      "adept : 0.638480209963504\n",
      "admirable : 0.684036251764562\n",
      "admired : 0.7385894072789226\n",
      "adolescent : 0.5515630588785644\n",
      "adored : 0.7176130238597255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "lexicon_trained = {}\n",
    "\n",
    "# Create a pipeline with StandardScaler and SVR, wrapped in MultiOutputRegressor\n",
    "model = MultiOutputRegressor(make_pipeline(StandardScaler(), SVR(kernel='rbf', C=1.0)))\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for key in lexicon.keys():\n",
    "    x_train.append(adjectives_scored[key])\n",
    "    y_train.append([lexicon[key], 0])\n",
    "\n",
    "x_train_np = np.array(x_train)\n",
    "y_train_np = np.array(y_train)\n",
    "\n",
    "    # Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "for key in adjectives_scored:\n",
    "    result = model.predict([adjectives_scored[key]])\n",
    "    lexicon_trained[key] = result[0][0]\n",
    "\n",
    "# print(lexicon_trained)\n",
    "for key, value in itertools.islice(lexicon_trained.items(), 20):\n",
    "    print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic NLP techniques to extract mood score changes for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "def calculate_mood_series(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Tokenize text into words\n",
    "    words = word_tokenize(text)\n",
    "    # Apply lemmatization\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    mood_series = []\n",
    "    for word in lemmatized_words:\n",
    "        if word in lexicon_trained.keys():\n",
    "            mood_series.append(lexicon_trained[word])\n",
    "    return mood_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45973176454385156, 0.3325276673498717, 0.42756880944163317]\n"
     ]
    }
   ],
   "source": [
    "example_text = \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of light, it was the season of darkness, it was the spring of hope, it was the winter of despair.\"\n",
    "\n",
    "print(calculate_mood_series(example_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*may be try classification instead of regression? classify in positive and negative moods.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = {\n",
    "    \"anxious\": 0, \"furious\": 0, \"peaceful\": 1, \"hate\": 0, \"joyful\": 1, \n",
    "    \"unacceptable\": 0, \"thrilled\": 1, \"infuriating\": 0, \"irate\": 0, \n",
    "    \"terrible\": 0, \"nervous\": 0, \"melancholy\": 0, \"useless\": 0, \"depressed\": 1, \n",
    "    \"gloomy\": 0, \"serene\": 1, \"elated\": 1, \"ecstatic\": 1, \"overjoyed\": 1,\n",
    "    \"gleeful\": 1, \"cheerful\": 1, \"optimistic\": 1, \"buoyant\": 1, \"enthusiastic\": 1,\n",
    "    \"upbeat\": 1, \"festive\": 1, \"playful\": 1, \"vivacious\": 1, \"amused\": 1,\n",
    "    \"blissful\": 1, \"grateful\": 1, \"tranquil\": 1, \"relaxed\": 1, \"comfortable\": 1,\n",
    "    \"cozy\": 1, \"warm\": 1, \"inviting\": 1, \"satisfied\": 1, \"pleasant\": 1, \n",
    "    \"pleased\" : 1, \"happy\": 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ''\n",
    "\n",
    "with open('../resources/sets/english-adjectives.txt', 'r') as file:\n",
    "    data = file.read().replace('\\n', ',')\n",
    "\n",
    "adjectives = data.split(',')\n",
    "\n",
    "adjectives_scored = {}\n",
    "\n",
    "for adjective in adjectives:\n",
    "    if adjective in corpus:\n",
    "        adjectives_scored[adjective] = corpus[adjective]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abandoned : 1\n",
      "able : 1\n",
      "absolute : 1\n",
      "adorable : 1\n",
      "adventurous : 1\n",
      "academic : 1\n",
      "acceptable : 1\n",
      "acclaimed : 1\n",
      "accomplished : 1\n",
      "accurate : 1\n",
      "aching : 1\n",
      "acidic : 1\n",
      "acrobatic : 1\n",
      "active : 1\n",
      "actual : 1\n",
      "adept : 1\n",
      "admirable : 1\n",
      "admired : 1\n",
      "adolescent : 1\n",
      "adored : 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lexicon_trained = {}\n",
    "\n",
    "# Create a pipeline with StandardScaler and SVR, wrapped in MultiOutputRegressor\n",
    "model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for key in lexicon.keys():\n",
    "    x_train.append(adjectives_scored[key])\n",
    "    y_train.append(lexicon[key])\n",
    "\n",
    "x_train_prepared = x_train\n",
    "y_train_prepared = np.array(list(lexicon.values()))\n",
    "\n",
    "    # Train the model\n",
    "model.fit(x_train_prepared, y_train_prepared)\n",
    "\n",
    "for key in adjectives_scored:\n",
    "    result = model.predict([adjectives_scored[key]])\n",
    "    lexicon_trained[key] = result[0]\n",
    "\n",
    "# print(lexicon_trained)\n",
    "for key, value in itertools.islice(lexicon_trained.items(), 20):\n",
    "    print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try emojis/punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ðŸŒ', 'âœ¨', 'ðŸ˜„', 'ðŸš€', 'ðŸŒž', 'ðŸŽ‰', 'â˜•', 'ðŸ‘‹', 'ðŸŒˆ']\n",
      "[':globe_showing_Europe-Africa:', ':sparkles:', ':grinning_face_with_smiling_eyes:', ':rocket:', ':sun_with_face:', ':party_popper:', ':hot_beverage:', ':waving_hand:', ':rainbow:']\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "# def extract_emojis(s):\n",
    "#   return ''.join(c for c in s if c in emoji.distinct_emoji_list('en'))\n",
    "\n",
    "example_text = \"Hey there! ðŸ‘‹ How's your day going? ðŸŒž Whether you're sipping coffee â˜•, exploring new places ðŸŒ, or just chilling at home ï¿½, I hope it's amazing! ðŸŽ‰ Don't forget to smile ðŸ˜„ and spread positivity! âœ¨ Life's a journey ðŸš€, so enjoy every moment! ðŸŒˆâœ¨\"\n",
    "emoji_list = emoji.distinct_emoji_list(example_text)\n",
    "print(emoji_list)\n",
    "\n",
    "unicode_values = [emoji.demojize(e).encode('unicode_escape').decode('utf-8') for e in emoji_list]\n",
    "print(unicode_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use two markers at the same time: text mood classifications (positive negative -> function) and emoji+punctuation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
